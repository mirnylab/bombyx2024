{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eabeadfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3452002/2321069392.py:20: DeprecationWarning: Please use `gaussian_filter1d` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import gaussian_filter1d\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import pickle \n",
    "import traceback\n",
    "\n",
    "import h5py\n",
    "import json\n",
    "from copy import deepcopy as dcopy\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from scipy.interpolate import interp1d, interp2d\n",
    "\n",
    "import polychrom\n",
    "from polychrom import polymer_analyses, contactmaps, polymerutils\n",
    "from polychrom.hdf5_format import list_URIs, load_URI, HDF5Reporter\n",
    "\n",
    "import cooltools.lib.plotting\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from cooltools.lib import numutils\n",
    "\n",
    "import simutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7de0c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_diags(hmap, ignore_diags):\n",
    "    hmap_diag_filtered = np.copy(hmap)\n",
    "    for i in range(ignore_diags):\n",
    "        np.fill_diagonal(hmap_diag_filtered[:, i:], np.nan)\n",
    "        np.fill_diagonal(hmap_diag_filtered[i:, :], np.nan)\n",
    "    return hmap_diag_filtered\n",
    "\n",
    "def calc_ixns(subcomps_coarsened, ooe, n_diags=[0,0]):\n",
    "    if n_diags:\n",
    "        trans_ooe = filter_diags(ooe, n_diags[1])\n",
    "        cis_ooe = filter_diags(ooe, n_diags[0])\n",
    "    else:\n",
    "        trans_ooe = cis_ooe = ooe\n",
    "\n",
    "    mean_ixns = np.nan*np.ones((4,4))\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            mean_ixns[i][j] = np.nanmean(trans_ooe[subcomps_coarsened==i].T[subcomps_coarsened==j])\n",
    "    #mean_ixns[0:2, 3] = mean_ixns[0:2, 2]\n",
    "    #mean_ixns[3, 0:2] = mean_ixns[2, 0:2]\n",
    "\n",
    "    x_loc = subcomps_coarsened == 2\n",
    "\n",
    "    XX_inter_mask = np.zeros((ooe.shape[0], ooe.shape[0]))\n",
    "    XX_intra_mask = np.zeros((ooe.shape[0], ooe.shape[0]))\n",
    "    for i in np.where(x_loc)[0]:\n",
    "        for j in np.where(x_loc)[0]:\n",
    "            XX_inter_mask[i,j] = (np.sum(x_loc[i:j]) < j-i)\n",
    "            XX_intra_mask[i,j] = (np.sum(x_loc[i:j]) == j-i)\n",
    "    XX_inter_mask = XX_inter_mask.astype(bool)\n",
    "    XX_intra_mask = XX_intra_mask.astype(bool)\n",
    "\n",
    "    mean_inter_X = np.nanmean(np.ma.array(trans_ooe, mask=~XX_inter_mask).compressed())    \n",
    "    mean_intra_X = np.nanmean(np.ma.array(cis_ooe, mask=~XX_intra_mask).compressed())\n",
    "    \n",
    "    mean_ixns[2,2] = mean_inter_X\n",
    "    mean_ixns[3,3] = mean_intra_X\n",
    "    \n",
    "    return mean_ixns\n",
    "\n",
    "def make_ixn_df(sim_group_path, mtx_fh, AB_self_attr, XX=0):\n",
    "    aa_list = []\n",
    "    ab_list = []\n",
    "    bb_list = []\n",
    "    ax_list = []\n",
    "    bx_list = []\n",
    "    xx_intra_list = []\n",
    "    xx_inter_list = []\n",
    "    \n",
    "\n",
    "    for AB in AB_self_attr:\n",
    "        comp_dir = f'AA{AB:.2f}_BB{AB:.2f}_XX{XX:.2f}'\n",
    "        sim_dir = 'Xboundaries'\n",
    "        hmap_path = f'{sim_group_path}/{comp_dir}/{sim_dir}/results/heatmaps'\n",
    "        if os.path.exists(f'{hmap_path}/{mtx_fh}'):\n",
    "            with open(f'{hmap_path}/{mtx_fh}', 'rb') as o:\n",
    "                mean_ixns = np.load(o)\n",
    "            aa_list.append(mean_ixns[0,0])\n",
    "            ab_list.append(mean_ixns[0,1])\n",
    "            bb_list.append(mean_ixns[1,1])\n",
    "            ax_list.append(mean_ixns[0,2])\n",
    "            bx_list.append(mean_ixns[1,2])\n",
    "            xx_inter_list.append(mean_ixns[2,2])\n",
    "            xx_intra_list.append(mean_ixns[3,3])\n",
    "        else:\n",
    "            aa_list.append(np.nan)\n",
    "            ab_list.append(np.nan)\n",
    "            bb_list.append(np.nan)\n",
    "            ax_list.append(np.nan)\n",
    "            bx_list.append(np.nan)\n",
    "            xx_inter_list.append(np.nan)\n",
    "            xx_intra_list.append(np.nan)\n",
    "\n",
    "\n",
    "    ixn_df = pd.DataFrame({\n",
    "        \"AA\": aa_list,\n",
    "        \"AB\": ab_list,\n",
    "        \"BB\": bb_list,\n",
    "        \"AS\": ax_list,\n",
    "        \"BS\": bx_list,\n",
    "        \"SS_inter\": xx_inter_list,\n",
    "        \"SS_intra\": xx_intra_list,\n",
    "    })\n",
    "\n",
    "    ixn_df['AA_attr'] = AB_self_attr\n",
    "    ixn_df['BB_attr'] = AB_self_attr\n",
    "    ixn_df['SS_attr'] = XX\n",
    "    \n",
    "    return ixn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38e02960",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_rad = 5 \n",
    "binSize = 5\n",
    "base_path = f'/net/levsha/share/emily/notebooks/sims/bombyx/toy_models'\n",
    "\n",
    "sim_dir = 'SC-10pol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4a1b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load compartment labels\n",
    "with open('../polymer_info.pkl', 'rb') as f:\n",
    "    monInfo = pickle.load(f)\n",
    "      \n",
    "chroms = monInfo['chroms']\n",
    "L = monInfo['L']\n",
    "n_per_chain = monInfo['L']//binSize\n",
    "n_chains = 30\n",
    "n_chains_per_sphere = 10\n",
    "\n",
    "mon_id_tmp = monInfo['compartment_ID']\n",
    "mon_id = np.array([mon_id_tmp[i] for i in range(0, L, binSize)])\n",
    "\n",
    "A_self_attr = [0.00, 0.025, 0.0375, 0.05, 0.075, 0.1]\n",
    "B_self_attr = A_self_attr\n",
    "X_self_attr = [0.00, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "699160d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoomify all of the matrices\n",
    "for AA in A_self_attr:\n",
    "    for BB in B_self_attr:\n",
    "        for XX in X_self_attr:\n",
    "            comp_dir = f'AA{AA:.2f}_BB{BB:.2f}_XX{XX:.2f}'\n",
    "            sim = f'{comp_dir}__{sim_dir}'   \n",
    "            \n",
    "            sim_path = f'{base_path}/compartments_only/sweep_output/{comp_dir}/{sim_dir}'\n",
    "            sim = f'{comp_dir}__{sim_dir}'\n",
    "            hmap_fh = f'{sim}__cutoff-{cutoff_rad:04.1f}_binSize-{binSize}_IC_chainMap.npy'\n",
    "\n",
    "            if os.path.exists(f'{sim_path}/results/heatmaps/{hmap_fh}'):\n",
    "                continue\n",
    "            else:\n",
    "                hmap_fh_unbinned = f'{sim}__cutoff-{cutoff_rad:04.1f}_binSize-1_IC_chainMap.npy'\n",
    "                if os.path.exists(f'{sim_path}/results/heatmaps/{hmap_fh_unbinned}'):\n",
    "                    mat = np.load(f'{sim_path}/results/heatmaps/{hmap_fh_unbinned}')\n",
    "                    mat = mat/np.mean(np.diag(mat,k=1))\n",
    "                    mat_binned = numutils.zoom_array(mat, (L/binSize,L/binSize))\n",
    "\n",
    "                    save_fh = f'{sim}__cutoff-{cutoff_rad:04.1f}_binSize-{binSize}_IC_chainMap.npy'\n",
    "                    with open(f'{sim_path}/results/heatmaps/{save_fh}', 'wb') as f:\n",
    "                        np.save(f, mat_binned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1fe0ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/levsha/share/emily/notebooks/sims/bombyx/toy_models/compartments_only/simutils.py:61: RuntimeWarning: divide by zero encountered in log10\n",
      "  x = np.log10(bins)\n",
      "/net/levsha/share/emily/notebooks/sims/bombyx/toy_models/compartments_only/simutils.py:62: RuntimeWarning: divide by zero encountered in log10\n",
      "  y = np.log10(Ps)\n",
      "/net/levsha/share/emily/notebooks/sims/bombyx/toy_models/compartments_only/simutils.py:67: RuntimeWarning: divide by zero encountered in log10\n",
      "  interp_x = np.log10(np.arange(last_bin))\n"
     ]
    }
   ],
   "source": [
    "# Taking expected from neutral chain\n",
    "Ps_comp_dir = f'AA{0:.2f}_BB{0:.2f}_XX{0:.2f}'\n",
    "Ps_sim_dir = 'SC-10pol'\n",
    "Ps_sim_path = f'{base_path}/compartments_only/sweep_output/{Ps_comp_dir}/{Ps_sim_dir}'\n",
    "Ps_fh = f'{Ps_comp_dir}__{Ps_sim_dir}__cutoff{cutoff_rad:04.1f}.txt'\n",
    "Ps = pd.read_csv(f'{Ps_sim_path}/results/Ps_scaling/{Ps_fh}', sep='\\t')\n",
    "\n",
    "x, y = simutils.interpolate_Ps(Ps['dist'].values, Ps['Ps'].values, L)\n",
    "y = y/chroms\n",
    "y = y/y[1]\n",
    "exp_2bin = numutils.LazyToeplitz(y)\n",
    "exp = numutils.zoom_array(exp_2bin[:,:], (n_per_chain,n_per_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "999e1efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for AA in A_self_attr:\n",
    "    for BB in B_self_attr:\n",
    "        for XX in X_self_attr:\n",
    "            comp_dir = f'AA{AA:.2f}_BB{BB:.2f}_XX{XX:.2f}'\n",
    "            sim = f'{comp_dir}__{sim_dir}'   \n",
    "            \n",
    "            sim_path = f'{base_path}/compartments_only/sweep_output/{comp_dir}/{sim_dir}'\n",
    "            sim = f'{comp_dir}__{sim_dir}'\n",
    "            ooe_fh = f'{sim}__cutoff-{cutoff_rad:04.1f}_binSize-{binSize}_IC_OOE_chainMap.npy'\n",
    "\n",
    "            if os.path.exists(f'{sim_path}/results/heatmaps/{ooe_fh}'):\n",
    "                continue\n",
    "            else:\n",
    "                hmap_fh = f'{sim}__cutoff-{cutoff_rad:04.1f}_binSize-{binSize}_IC_chainMap.npy'\n",
    "                if os.path.exists(f'{sim_path}/results/heatmaps/{hmap_fh}'):\n",
    "                    mat = np.load(f'{sim_path}/results/heatmaps/{hmap_fh}')\n",
    "                    mat = mat/np.mean(np.diag(mat,k=1))\n",
    "\n",
    "                    ooe = mat/exp[:,:]\n",
    "\n",
    "                    with open(f'{sim_path}/results/heatmaps/{ooe_fh}', 'wb') as f:\n",
    "                        np.save(f, ooe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46f289e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean interactions for AA0.00_BB0.00_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.00_BB0.00_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.00_BB0.00_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.00_BB0.03_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.00_BB0.03_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.00_BB0.03_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.00_BB0.04_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.00_BB0.04_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.00_BB0.04_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.00_BB0.05_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.00_BB0.05_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.00_BB0.05_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.00_BB0.07_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.00_BB0.07_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.00_BB0.07_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.00_BB0.10_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.00_BB0.10_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.03_BB0.00_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.03_BB0.00_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.03_BB0.00_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.03_BB0.03_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.03_BB0.03_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.03_BB0.03_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.03_BB0.04_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.03_BB0.04_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.03_BB0.04_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.03_BB0.05_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.03_BB0.05_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.03_BB0.05_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.03_BB0.07_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.03_BB0.07_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.03_BB0.07_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.03_BB0.10_XX0.00__SC-10pol already exist\n",
      "computing ixns for /net/levsha/share/emily/notebooks/sims/bombyx/toy_models/compartments_only/sweep_output/AA0.03_BB0.10_XX0.05/SC-10pol\n",
      "mean interactions for AA0.04_BB0.00_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.04_BB0.00_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.04_BB0.00_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.04_BB0.03_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.04_BB0.03_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.04_BB0.03_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.04_BB0.04_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.04_BB0.04_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.04_BB0.04_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.04_BB0.05_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.04_BB0.05_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.04_BB0.05_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.04_BB0.07_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.04_BB0.07_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.04_BB0.07_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.00_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.00_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.00_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.03_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.03_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.03_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.04_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.04_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.04_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.05_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.05_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.05_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.07_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.07_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.07_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.10_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.05_BB0.10_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.00_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.00_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.00_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.03_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.03_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.03_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.04_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.04_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.04_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.05_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.05_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.05_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.07_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.07_XX0.03__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.07_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.10_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.07_BB0.10_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.10_BB0.00_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.10_BB0.00_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.10_BB0.03_XX0.00__SC-10pol already exist\n",
      "computing ixns for /net/levsha/share/emily/notebooks/sims/bombyx/toy_models/compartments_only/sweep_output/AA0.10_BB0.03_XX0.05/SC-10pol\n",
      "mean interactions for AA0.10_BB0.05_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.10_BB0.05_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.10_BB0.07_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.10_BB0.07_XX0.05__SC-10pol already exist\n",
      "mean interactions for AA0.10_BB0.10_XX0.00__SC-10pol already exist\n",
      "mean interactions for AA0.10_BB0.10_XX0.05__SC-10pol already exist\n"
     ]
    }
   ],
   "source": [
    "comp_sizes = np.diff(np.concatenate([np.array([0]), np.where(np.diff(mon_id) != 0)[0]]))\n",
    "biggest_comp = max(comp_sizes)\n",
    "\n",
    "mtx_fh = f'mean_ixns.npy'\n",
    "for AA in A_self_attr:\n",
    "    for BB in B_self_attr:\n",
    "        for XX in X_self_attr:\n",
    "            comp_dir = f'AA{AA:.2f}_BB{BB:.2f}_XX{XX:.2f}'\n",
    "            sim = f'{comp_dir}__{sim_dir}'   \n",
    "            \n",
    "            sim_path = f'{base_path}/compartments_only/sweep_output/{comp_dir}/{sim_dir}'\n",
    "            sim = f'{comp_dir}__{sim_dir}'   \n",
    "        \n",
    "            ooe_fh = f'{sim}__cutoff-{cutoff_rad:04.1f}_binSize-{binSize}_IC_OOE_chainMap.npy'\n",
    "\n",
    "            try:\n",
    "                ooe = np.load(f'{sim_path}/results/heatmaps/{ooe_fh}')\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            if os.path.exists(f'{sim_path}/results/heatmaps/{mtx_fh}'):\n",
    "                print(f'mean interactions for {sim} already exist')\n",
    "                continue\n",
    "            else:\n",
    "                print(f'computing ixns for {sim_path}')\n",
    "                mean_ixns = calc_ixns(subcomps_coarsened=mon_id, ooe=ooe, n_diags=[2,biggest_comp])\n",
    "                with open(f'{sim_path}/results/heatmaps/{mtx_fh}', 'wb') as o:\n",
    "                    np.save(o, mean_ixns)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e746a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
